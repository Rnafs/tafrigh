{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8NgMnd42sOt"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "  <center>\n",
        "    <img src=\"https://user-images.githubusercontent.com/7662492/229289746-89c5a4c7-afa6-4d46-a0e6-63dfdeb98285.jpg\" width=\"250px\"/>\n",
        "\n",
        "  <h1>تفريغ - الكتب المُيسّرة</h1>\n",
        "  </center>\n",
        "\n",
        "  <p>مرحبًا بك في تفريغ لتفريغ المواد الصوتية والمرئية باستخدام تقنيات الذكاء الاصطناعي. لاستخدام تفريغ:</p>\n",
        "\n",
        "  <ol>\n",
        "    <li>قم بإدخال روابط المواد المطلوب تحويلها من منصة YouTube أو أي منصة أخرى في حقل \"urls\" وتأكد من فصلها بمسافة، أو قم بترك الحقل فارغًا لتفريغ المواد التي قمت برفعها</li>\n",
        "    <li>(اختياري) قم بتحديد أقل عدد من الكلمات في كل جزء من أجزاء التفريغ. يؤثر هذا في طول الأجزاء التي سيتم تفريغها</li>\n",
        "    <li>\n",
        "      إذا كنت تريد استخدام مجموعة نماذج Whisper:\n",
        "      <ul>\n",
        "        <li>قم باختيار النموذج المُراد استخدامه في حقل \"model\"</li>\n",
        "        <li>قم باختيار لغة المادة في حقل \"language\"</li>\n",
        "        <li>قم باختيار المهمة المُراد إنجازها في حقل \"task\" سواء كانت تفريغ المادة أو ترجمتها للانجليزية</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "    <li>\n",
        "      إذا كنت تريد استخدام تقنية wit.ai:\n",
        "      <ul>\n",
        "        <li>قم بوضع مفتاح wit.ai الخاص بك في حقل \"wit_api_key\"</li>\n",
        "        <li>(اختياري) قم بتحديد أقصى مدة للتقطيع والتي ستؤثر على طول الجمل في ملف المخرجات</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "    <li>قم بتشغيل الخلية في الأسفل من خلال الضغط على الدائرة المحتوية على السهم</li>\n",
        "  </ol>\n",
        "\n",
        "  <p>يمكنك تجربة التفريغ باستخدام نماذج Whisper وتقنية wit.ai واستخدام التفريغ الأفضل لحالتك. كملاحظة عامة، نماذج Whisper تقوم بتفريغ الهمزات والتشكيلات وعلامات الترقيم بشكل أفضل من wit.ai، لكن wit.ai يُنتج أخطاء إملائية أقل.</p>\n",
        "\n",
        "  <p>عندما ينتهي التحويل سيتم تنزيل الملفات النصية بشكل تلقائي بصيغة <code>txt</code> و <code>srt</code> وسيكون اسم الملف هو مُعرّف المادة على منصة YouTube الذي يكون في آخر رابط المادة: https://youtu.be/<strong>4h5P7jXvW98</strong>.</p>\n",
        "\n",
        "  <hr>\n",
        "\n",
        "  <p>يمكنك متابعة مشروع <strong>الكتب المُيسّرة</strong> والتواصل معنا من خلال:</p>\n",
        "\n",
        "  <ul>\n",
        "    <li><a href=\"https://t.me/ieasybooks\">قناتنا على تيليجرام</a></li>\n",
        "    <li><a href=\"https://www.youtube.com/@ieasybooks\">قناتنا على يوتيوب</a></li>\n",
        "    <li><a href=\"https://twitter.com/iieasybooks\">حسابنا على تويتر</a></li>\n",
        "    <li><a href=\"https://www.facebook.com/ieasybooks\">صفحتنا على فيسبوك</a></li>\n",
        "    <li><a href=\"https://github.com/ieasybooks\">حسابنا على GitHub (للمبرمجين)</a></li>\n",
        "    <li>بريدنا الالكتروني: easybooksdev@gmail.com</li>\n",
        "  </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "uY05i198xi3D",
        "outputId": "5438c2fb-b89d-41ac-abe3-c69868ab3f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جارٍ تجهيز بيئة العمل.\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "جارٍ تحويل المواد إلى نصوص باستخدام نماذج Whisper.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rURLs or local paths:   0%|          | 0/1 [00:00<?, ?it/s]ERROR: unable to download video data: HTTP Error 403: Forbidden\n",
            "ERROR: unable to download video data: HTTP Error 403: Forbidden\n",
            "ERROR: unable to download video data: HTTP Error 403: Forbidden\n",
            "ERROR: unable to download video data: HTTP Error 403: Forbidden\n",
            "\n",
            "URL elements:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "URLs or local paths:   0%|          | 0/1 [00:22<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'output/AVP6biY-llA.mp3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-67ba0ecaa6c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfarrigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Download all txt and srt files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tafrigh/cli.py\u001b[0m in \u001b[0;36mfarrigh\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mprogress_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(https?://)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mprogress_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_elements_segments\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0msegments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_elements_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mprogress_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tafrigh/cli.py\u001b[0m in \u001b[0;36mprocess_url\u001b[0;34m(url, model, config, progress_info)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mnew_progress_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecognize_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mnew_progress_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tafrigh/recognizers/whisper_recognizer.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, file_path, model, whisper_config)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m           \u001b[0;32myield\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhisper_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tafrigh/recognizers/whisper_recognizer.py\u001b[0m in \u001b[0;36m_recognize_faster_whisper\u001b[0;34m(self, audio_file_path, model, whisper_config)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mwhisper_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhisper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   ) -> Generator[dict[str, float], None, list[SegmentType]]:\n\u001b[0;32m---> 70\u001b[0;31m     segments, info = model.transcribe(\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhisper_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/faster_whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(self, audio, language, task, log_progress, beam_size, best_of, patience, length_penalty, repetition_penalty, no_repeat_ngram_size, temperature, compression_ratio_threshold, log_prob_threshold, no_speech_threshold, condition_on_previous_text, prompt_reset_on_temperature, initial_prompt, prefix, suppress_blank, suppress_tokens, without_timestamps, max_initial_timestamp, word_timestamps, prepend_punctuations, append_punctuations, multilingual, vad_filter, vad_parameters, max_new_tokens, chunk_length, clip_timestamps, hallucination_silence_threshold, hotwords, language_detection_threshold, language_detection_segments)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/faster_whisper/audio.py\u001b[0m in \u001b[0;36mdecode_audio\u001b[0;34m(input_file, sampling_rate, split_stereo)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ignore_invalid_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/av/container/core.pyx\u001b[0m in \u001b[0;36mav.container.core.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/av/container/core.pyx\u001b[0m in \u001b[0;36mav.container.core.Container.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/av/container/core.pyx\u001b[0m in \u001b[0;36mav.container.core.Container.err_check\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/av/error.pyx\u001b[0m in \u001b[0;36mav.error.err_check\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/AVP6biY-llA.mp3'"
          ]
        }
      ],
      "source": [
        "# @title <h1><center>تفريغ</center></h1>\n",
        "\n",
        "print('جارٍ تجهيز بيئة العمل.')\n",
        "\n",
        "# Setup Tafrigh.\n",
        "!apt-get install -q portaudio19-dev python3-pyaudio > pyaudio_fix_logs.txt\n",
        "%pip install -U tafrigh[wit,whisper]==1.7.5 > install_logs.txt\n",
        "%pip install -U yt-dlp > update_yt_dlp_logs.txt\n",
        "\n",
        "# Start: Quick fix related to Colab, HuggingFace, and faster-whisper.\n",
        "!apt install libcublas11 > fix_logs.txt\n",
        "!pip install ctranslate2==4.4.0 > ctranslate2_downgrade_logs.txt\n",
        "\n",
        "from huggingface_hub.utils import _runtime\n",
        "_runtime._is_google_colab = False\n",
        "# End: Quick fix related to Colab, HuggingFace, and faster-whisper.\n",
        "\n",
        "# Get inputs.\n",
        "\n",
        "# @markdown <h1 dir=\"rtl\">مدخلات عامة</h1>\n",
        "\n",
        "# @markdown <p dir=\"rtl\">روابط المواد المطلوب تفريغها وتأكد من فصلها بمسافة، أو أترك الحقل فارغًا لتفريغ المواد التي قمت برفعها</p>\n",
        "urls = 'https://youtu.be/AVP6biY-llA?t=438'  # @param { type: \"string\" }\n",
        "\n",
        "# @markdown <p dir=\"rtl\">أقل عدد من الكلمات في كل جزء من أجزاء التفريغ</p>\n",
        "min_words_per_segment = 1  # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown <h1 dir=\"rtl\">مدخلات خاصة بنماذج Whisper</h1>\n",
        "\n",
        "# @markdown <p dir=\"rtl\">النموذج المُراد استخدامه للتفريغ</p>\n",
        "model = 'large-v3 (\\u0623\\u0641\\u0636\\u0644 \\u062F\\u0642\\u0629)'  # @param [\"large-v3 (أفضل دقة)\", \"medium\", \"base\", \"small\", \"tiny (أقل دقة)\"]\n",
        "\n",
        "# @markdown <p dir=\"rtl\">(اختياري) لغة المادة</p>\n",
        "language = 'ar'  # @param [\"ar\", \"af\", \"am\", \"as\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"bo\", \"br\", \"bs\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"en\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fo\", \"fr\", \"gl\", \"gu\", \"ha\", \"haw\", \"he\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"is\", \"it\", \"ja\", \"jw\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"la\", \"lb\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\", \"ne\", \"nl\", \"nn\", \"no\", \"oc\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sa\", \"sd\", \"si\", \"sk\", \"sl\", \"sn\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\", \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"uk\", \"ur\", \"uz\", \"vi\", \"yi\", \"yo\", \"zh\"]\n",
        "\n",
        "# @markdown <p dir=\"rtl\">(اختياري) المهمة</p>\n",
        "task = 'تفريغ'  # @param [\"تفريغ\", \"ترجمة\"]\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown <h1 dir=\"rtl\">مدخلات خاصة بتقنية wit.ai</h1>\n",
        "\n",
        "# @markdown <p dir=\"rtl\">المفتاح الخاص بك على موقع wit.ai</p>\n",
        "wit_api_key = ''  # @param { type: \"string\" }\n",
        "\n",
        "# @markdown <p dir=\"rtl\">(اختياري) أقصى مدة للتقطيع والتي ستؤثر على طول الجمل في ملف SRT</p>\n",
        "max_cutting_duration = 15  # @param {type:\"slider\", min:1, max:17, step:1}\n",
        "\n",
        "if model == 'large-v3 (\\u0623\\u0641\\u0636\\u0644 \\u062F\\u0642\\u0629)':\n",
        "    model = 'large-v3'\n",
        "elif model == 'tiny (\\u0623\\u0642\\u0644 \\u062F\\u0642\\u0629)':\n",
        "    model = 'tiny'\n",
        "\n",
        "if task == 'تفريغ':\n",
        "  task = 'transcribe'\n",
        "elif task == 'ترجمة':\n",
        "  task = 'translate'\n",
        "\n",
        "# Imports.\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "from google.colab import files\n",
        "from tafrigh import farrigh, Config\n",
        "\n",
        "# Setup directories.\n",
        "output_dir = 'output'\n",
        "if not os.path.exists(output_dir):\n",
        "  os.mkdir(output_dir)\n",
        "\n",
        "# Start Tafrigh.\n",
        "if wit_api_key:\n",
        "  print('جارٍ تحويل المواد إلى نصوص باستخدام تقنيات wit.ai.')\n",
        "else:\n",
        "  print('جارٍ تحويل المواد إلى نصوص باستخدام نماذج Whisper.')\n",
        "\n",
        "config = Config(\n",
        "  input=Config.Input(\n",
        "    urls_or_paths=list(map(str.strip, urls.split(' '))) if len(urls.strip()) else ['.'],\n",
        "    skip_if_output_exist=False,\n",
        "    download_retries=3,\n",
        "    yt_dlp_options='{}',\n",
        "    verbose=False,\n",
        "  ),\n",
        "  whisper=Config.Whisper(\n",
        "    model_name_or_path=model,\n",
        "    task=task,\n",
        "    language=language,\n",
        "    use_faster_whisper=True,\n",
        "    beam_size=5,\n",
        "    ct2_compute_type='default',\n",
        "  ),\n",
        "  wit=Config.Wit(\n",
        "    wit_client_access_tokens=None if len(wit_api_key.strip()) == 0 else wit_api_key.split(),\n",
        "    max_cutting_duration=max_cutting_duration,\n",
        "  ),\n",
        "  output=Config.Output(\n",
        "    min_words_per_segment=min_words_per_segment,\n",
        "    save_files_before_compact=False,\n",
        "    save_yt_dlp_responses=False,\n",
        "    output_sample=0,\n",
        "    output_formats=['txt', 'srt'],\n",
        "    output_dir=output_dir,\n",
        "  ),\n",
        ")\n",
        "\n",
        "deque(farrigh(config), maxlen=0)\n",
        "\n",
        "# Download all txt and srt files.\n",
        "print('جارٍ تنزيل الملفات النصية.')\n",
        "\n",
        "txt_files = glob.glob(f\"{output_dir}/*.txt\")\n",
        "srt_files = glob.glob(f\"{output_dir}/*.srt\")\n",
        "\n",
        "try:\n",
        "  txt_files.remove('output/archive.txt')\n",
        "except ValueError:\n",
        "  pass\n",
        "\n",
        "for file in txt_files + srt_files:\n",
        "  files.download(file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}